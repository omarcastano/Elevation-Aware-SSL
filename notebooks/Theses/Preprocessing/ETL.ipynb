{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "executionInfo": {
                    "elapsed": 3848,
                    "status": "ok",
                    "timestamp": 1659064816738,
                    "user": {
                        "displayName": "Omar Andres Casta√±o",
                        "userId": "15147820125606867511"
                    },
                    "user_tz": 300
                },
                "id": "h0CQB1Rcced4"
            },
            "outputs": [],
            "source": [
                "#import geopandas as gpd\n",
                "import matplotlib.pyplot as plt\n",
                "#import pyproj\n",
                "import pandas as pd\n",
                "import h5py    \n",
                "import os\n",
                "from shapely.geometry import Point, Polygon, MultiPolygon\n",
                "import numpy as np\n",
                "#import elevation_aware_ssl.preprocessing as DP\n",
                "from shapely.geometry import Polygon\n",
                "from osgeo import osr, gdal, ogr\n",
                "import torch\n",
                "import geopandas as gpd\n",
                "from elevation_aware_ssl import preprocessing as dp\n",
                "import pickle\n",
                "import tempfile\n",
                "from tqdm import tqdm\n",
                "from elevation_aware_ssl import EDA\n",
                "import os\n",
                "from IPython.display import clear_output\n",
                "import re"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "letters=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
                "letters_map=[{l:i for i, l in enumerate(letters)}][0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_patch_shapefile(patch_name, path_to_folders, frontera, unique_labels):\n",
                "\n",
                "    coor = []\n",
                "    for chip in metadata.query(f\"patch=='{patch_name}'\").image:\n",
                "\n",
                "        path_to_chip_metadata = path_to_folders + \"/\" + chip + \"/metadata.pkl\"\n",
                "        corners = pd.read_pickle(path_to_chip_metadata)[\"corners\"]\n",
                "        nw_x, nw_y = corners[\"nw\"][::-1]\n",
                "        se_x, se_y = corners[\"se\"][::-1]\n",
                "        coor.append([nw_x, nw_y, se_x, se_y])\n",
                "\n",
                "    nw_x = np.array(coor)[:, 0].min()\n",
                "    nw_y = np.array(coor)[:, 1].max()\n",
                "    se_x = np.array(coor)[:, 2].max()\n",
                "    se_y = np.array(coor)[:, 3].min()\n",
                "    metadata_coor = {\"corners\": {\"nw\": np.array([nw_y, nw_x]), \"se\": np.array([se_y, se_x])}}\n",
                "\n",
                "    with tempfile.NamedTemporaryFile(\"wb\") as temp:\n",
                "        pickle.dump(metadata_coor, temp)\n",
                "        temp.flush()\n",
                "        patch_reference = patch_name\n",
                "        gdf_chip = dp.create_shapefiel_from_polygons(temp.name, patch_reference, chip_padding=0.001, crs=\"epsg:3116\")\n",
                "\n",
                "\n",
                "    gdf_intersection = dp.polygons_intersection(frontera, gdf_chip, unique_labels, patch_reference)\n",
                "    gdf_intersection.rename({\"labels\": \"elemento\"}, axis=1, inplace=True)\n",
                "\n",
                "    return gdf_intersection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_dataset(metadata, frontera, path_temp_file, path_to_save_masks):\n",
                "\n",
                "    images = []\n",
                "    masks = []\n",
                "    root = []\n",
                "    id = []\n",
                "    geometry_intersection = []\n",
                "    current_patch = \"\"\n",
                "    unique_labels = frontera[\"elemento\"].unique()\n",
                "    unique_labels.sort()\n",
                "    print(unique_labels)\n",
                "    # metadata.sort_values(by=\"patch\", inplace=True)\n",
                "\n",
                "    for chip_metadata, patch_name, idx in zip(tqdm(metadata.image), metadata.patch, metadata.index):\n",
                "\n",
                "        chip_reference = chip_metadata.split(\"/\")[1]\n",
                "\n",
                "        # Create square polygons using chip metada\n",
                "        gdf_chip = dp.create_shapefiel_from_polygons(\n",
                "            f\"{path_to_folders}/{chip_metadata}/metadata.pkl\",\n",
                "            chip_reference,\n",
                "            chip_padding=0.0005,\n",
                "            crs=\"epsg:3116\",\n",
                "        )\n",
                "\n",
                "        # get patch shapefile\n",
                "        if current_patch != patch_name:\n",
                "            current_patch = patch_name\n",
                "            patch_shapefile = get_patch_shapefile(patch_name, path_to_folders, frontera, unique_labels)\n",
                "\n",
                "        # Intersecton between square polygons and SIPRA dataset\n",
                "        gdf_intersection = dp.polygons_intersection(patch_shapefile, gdf_chip, unique_labels, chip_reference)\n",
                "\n",
                "\n",
                "        if gdf_intersection.geometry.is_empty.sum() != 3:\n",
                "\n",
                "            img = EDA.read_numpy_image(f\"{path_to_data}/Dataset/{chip_metadata}/chip.npy\")\n",
                "            dp.from_array_to_geotiff(\n",
                "                f\"{path_to_data}/sentinel_geo_images/{chip_metadata}/chip.tif\",\n",
                "                img[:3],\n",
                "                f\"{path_to_data}/Dataset/{chip_metadata}/metadata.pkl\",\n",
                "                crs=3116,\n",
                "            )\n",
                "\n",
                "            gdf_intersection.to_file(path_temp_file + \"/temp.geojson\", driver=\"GeoJSON\")\n",
                "\n",
                "            # create labels masks\n",
                "            dp.shapefiel_to_geotiff(path_temp_file + \"/temp.geojson\", f\"temp/{chip_reference}.tif\", 10, \"labels_num\", no_data_value=999)\n",
                "\n",
                "            if not os.path.isdir(path_to_save_masks + f\"/{chip_metadata}\"):\n",
                "                os.makedirs(path_to_save_masks + f\"/{chip_metadata}\")\n",
                "\n",
                "            dp.crop_geotiff_chip(\n",
                "                f\"{path_to_folders}/{chip_metadata}/metadata.pkl\",\n",
                "                f\"temp/{chip_reference}.tif\",\n",
                "                path_to_save_masks + f\"/{chip_metadata}/mask.tif\",\n",
                "            )\n",
                "\n",
                "            geometry_intersection.append(gdf_intersection)\n",
                "            masks.append(f\"{chip_metadata}/mask.tif\")\n",
                "            images.append(f\"{chip_metadata}/chip.npz\")\n",
                "\n",
                "            id_number = re.sub(r\"[a-zA-Z_\\(\\)\\,\\\\\\/\\s+]\", \"\", chip_metadata)\n",
                "            id_letter = re.sub(r\"[\\d_\\(\\)\\,\\\\\\/\\s+]\", \"\", chip_metadata)\n",
                "            id_letter = \"\".join(str(letters_map[l]) for l in id_letter[:3])\n",
                "\n",
                "            id.append(int(id_number + id_letter))\n",
                "            metadata = pd.DataFrame({\"Id\": id, \"Image\": images, \"Mask\": masks})\n",
                "\n",
                "            # clear_output()\n",
                "\n",
                "    gdf_intersection = pd.concat(geometry_intersection, ignore_index=True)\n",
                "    gdf_intersection.crs = \"epsg:3116\"\n",
                "    gdf_intersection.to_file(\"LabelGeoTiff/labels.shp\")\n",
                "\n",
                "    return gdf_intersection, metadata"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "path_to_data = \"/media/omar/storage/gdrive/Maestria/Datasets\" \n",
                "metadata = pd.read_csv(\"/media/omar/storage/gdrive/Maestria/Theses/Preprocessing/metadata_raw_images.csv\")\n",
                "#metadata = metadata.drop(labels=[52809, 52810, 58697, 58700], axis=0)\n",
                "metadata"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#path_to_frontera =f\"{path_to_data}/Frontera_Agricola_Nov2021/Frontera_Agricola_Nov2021.shp\"\n",
                "#frontera = gpd.read_file(path_to_frontera)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "frontera.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "path_to_folders = f\"{path_to_data}/Dataset\"\n",
                "path_temp_file = f\"{path_to_data}/temp\"\n",
                "path_to_save_masks = f\"{path_to_data}/LabelsGeoTiffv2\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gdf, new_metadata = create_dataset(metadata.query(\"patch == '18NTP'\").iloc[50:60].copy(), frontera, path_temp_file, path_to_save_masks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class_names = [\"non_agricultural_area\", \"legal_exclusions\", \"agricultural_frontier\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#print(new_metadata.shape)\n",
                "#new_metadata.to_csv(\"/media/omar/storage/gdrive/Maestria/Datasets/GeoDataset/LabelsGeoTiffv2/metadata.csv\", index=False)\n",
                "#new_metadata.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "old_metadata = pd.read_csv(f\"{path_to_data}/metadata/metadata.csv\")\n",
                "old_metadata = old_metadata.query(\"Patch == '18NTN'\")\n",
                "old_metadata.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "path_to_label = f\"{path_to_data}/LabelsGeoTiffv2/\"\n",
                "path_to_images = f\"{path_to_data}/Sentinel_2_Images/\"\n",
                "_ = EDA.visualize_images_and_masks(path_to_label, path_to_images, new_metadata.head(10), temporal_dim=False, n=7, figsize=(20, 7), class_names=class_names)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "path_to_label = f\"{path_to_data}/\"\n",
                "path_to_images = f\"{path_to_data}/Sentinel_2_Images/\"\n",
                "_ = EDA.visualize_images_and_masks(path_to_label, path_to_images, old_metadata.head(10), temporal_dim=False, n=7, figsize=(20, 7), class_names=class_names)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "colab": {
            "collapsed_sections": [],
            "machine_shape": "hm",
            "name": "DataPreprocessing.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3.7.13 64-bit ('elevation_aware_ssl')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.13"
        },
        "vscode": {
            "interpreter": {
                "hash": "81ba9a1503424c443a7bc1e1bbe8d83e046e09a72ec9317cd76d572ac910684c"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
